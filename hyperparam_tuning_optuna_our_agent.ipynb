{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Variables\n",
    "## Fixed\n",
    "tpm_hist = {}  # record tp metric values for trials\n",
    "tp_metric = 'avgwl'  # specified trade_param_metric: ratio avg value win/loss\n",
    "## Settable by User\n",
    "n_trials = 10  # number of HP optimization runs\n",
    "total_timesteps = 2000 # per HP optimization run\n",
    "total_episodes = 10\n",
    "## Logging callback params\n",
    "lc_threshold=1e-5\n",
    "lc_patience=15\n",
    "lc_trial_number=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyfolio-reloaded  #original pyfolio no longer maintained\n",
    "# !pip install optuna\n",
    "# !pip install -U \"ray[rllib]\"\n",
    "# !pip install plotly\n",
    "# !pip install ipywidgets\n",
    "# !pip install -U kaleido   # enables saving plots to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaleido in /home/neeraj/anaconda3/envs/ddpg_trading/lib/python3.8/site-packages (0.2.1)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neeraj/anaconda3/envs/ddpg_trading/lib/python3.8/site-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "import optuna\n",
    "from pathlib import Path\n",
    "from ddpg_torch import Agent\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import plotLearning\n",
    "# from config import *\n",
    "\n",
    "import config_tickers\n",
    "from download_data import process_data\n",
    "from stock_trading_env import StockTradingEnv\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from trade_stocks import trade_on_test_df\n",
    "# from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "import os\n",
    "import ray\n",
    "import kaleido\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f'Torch device: {device}')\n",
    "from plot import get_comparison_df, backtest_stats, backtest_plot, get_daily_return, get_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# data_path = './data/data_processed_DOW_30_TICKER_2009-01-01_to_2022-07-31.csv'\n",
    "# processed_full = pd.read_csv(data_path, index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_START_DATE = '2009-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_END_DATE = '2016-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRADE_START_DATE = '2016-01-01'\n",
    "TRADE_END_DATE = '2020-05-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_name_from_config_tickers = 'DOW_30_TICKER'\n",
    "\n",
    "TRAIN_CSV_NAME = f'./data/train_{ticker_name_from_config_tickers}_{TRAIN_START_DATE}_to_{TRAIN_END_DATE}.csv'\n",
    "TRADE_CSV_NAME = f'./data/trade_{ticker_name_from_config_tickers}_{TRADE_START_DATE}_to_{TRADE_END_DATE}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDICATORS = [\n",
    "            'macd',\n",
    "            'boll_ub',\n",
    "            'boll_lb',\n",
    "            'rsi_30',\n",
    "            'cci_30',\n",
    "            'dx_30',\n",
    "            'close_30_sma',\n",
    "            'close_60_sma'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = data_split(processed_full, '2009-01-01','2020-07-01')\n",
    "# trade = data_split(processed_full, '2020-05-01','2021-10-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = data_split(processed_full, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "# trade = data_split(processed_full, TRADE_START_DATE, TRADE_END_DATE)\n",
    "# print(f'Number of training samples: {len(train)}')\n",
    "# print(f'Number of testing samples: {len(trade)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading csvs...\n",
      "Train shape: (51098, 18) \n",
      " Trade shape: (31726, 18)\n"
     ]
    }
   ],
   "source": [
    "print('reading csvs...')\n",
    "train = pd.read_csv(TRAIN_CSV_NAME, index_col='Unnamed: 0')\n",
    "trade = pd.read_csv(TRADE_CSV_NAME, index_col='Unnamed: 0')\n",
    "\n",
    "print(f'Train shape: {train.shape} \\n Trade shape: {trade.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 291\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS) * stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the environment kwargs\n",
    "\n",
    "# env_kwargs = {\n",
    "#     \"hmax\": 100, \n",
    "#     \"initial_amount\": 1000000, \n",
    "#     \"buy_cost_pct\": 0.001,\n",
    "#     \"sell_cost_pct\": 0.001,\n",
    "#     \"state_space\": state_space, \n",
    "#     \"stock_dim\": stock_dimension, \n",
    "#     \"tech_indicator_list\": config.INDICATORS, \n",
    "#     \"action_space\": stock_dimension, \n",
    "#     \"reward_scaling\": 1e-4\n",
    "    \n",
    "# }\n",
    "# #Instantiate the training gym compatible environment\n",
    "# e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "\n",
    "#Instantiate the trading environment\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = None, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "e_train_gym.seed(SEED)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade performance code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main method\n",
    "# Calculates Trade Performance for Objective\n",
    "# Called from objective method\n",
    "# Returns selected trade perf metric(s)\n",
    "# Requires actions and associated prices\n",
    "\n",
    "def calc_trade_perf_metric(df_actions, \n",
    "                           df_prices_trade,\n",
    "                           tp_metric,\n",
    "                           dbg=False):\n",
    "  \n",
    "    df_actions_p, df_prices_p, tics = prep_data(df_actions.copy(),\n",
    "                                                df_prices_trade.copy())\n",
    "    # actions predicted by trained model on trade data\n",
    "    df_actions_p.to_csv('df_actions.csv') \n",
    "\n",
    "    \n",
    "    # Confirms that actions, prices and tics are consistent\n",
    "    df_actions_s, df_prices_s, tics_prtfl = \\\n",
    "        sync_tickers(df_actions_p.copy(),df_prices_p.copy(),tics)\n",
    "    \n",
    "    # copy to ensure that tics from portfolio remains unchanged\n",
    "    tics = tics_prtfl.copy()\n",
    "    \n",
    "    # Analysis is performed on each portfolio ticker\n",
    "    perf_data= collect_performance_data(df_actions_s, df_prices_s, tics)\n",
    "    # profit/loss for each ticker\n",
    "    pnl_all = calc_pnl_all(perf_data, tics)\n",
    "    # values for trade performance metrics\n",
    "    perf_results = calc_trade_perf(pnl_all)\n",
    "    df = pd.DataFrame.from_dict(perf_results, orient='index')\n",
    "    \n",
    "    # calculate and return trade metric value as objective\n",
    "    m = calc_trade_metric(df,tp_metric)\n",
    "    print(f'Ratio Avg Win/Avg Loss: {m}')\n",
    "    k = str(len(tpm_hist)+1)\n",
    "    # save metric value\n",
    "    tpm_hist[k] = m\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supporting methods\n",
    "def calc_trade_metric(df,metric='avgwl'):\n",
    "    '''# trades', '# wins', '# losses', 'wins total value', 'wins avg value',\n",
    "       'losses total value', 'losses avg value'''\n",
    "    # For this tutorial, the only metric available is the ratio of \n",
    "    #  average values of winning to losing trades. Others are in development.\n",
    "    \n",
    "    # some test cases produce no losing trades.\n",
    "    # The code below assigns a value as a multiple of the highest value during\n",
    "    # previous hp optimization runs. If the first run experiences no losses,\n",
    "    # a fixed value is assigned for the ratio\n",
    "    tpm_mult = 1.0\n",
    "    avgwl_no_losses = 25\n",
    "    if metric == 'avgwl':\n",
    "        if sum(df['# losses']) == 0:\n",
    "            try:\n",
    "                return max(tpm_hist.values())*tpm_mult\n",
    "            except ValueError:\n",
    "                return avgwl_no_losses\n",
    "        avg_w = sum(df['wins total value'])/sum(df['# wins'])\n",
    "        avg_l = sum(df['losses total value'])/sum(df['# losses'])\n",
    "        m = abs(avg_w/avg_l)\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def prep_data(df_actions,\n",
    "              df_prices_trade):\n",
    "    \n",
    "    df=df_prices_trade[['date','close','tic']]\n",
    "    df['Date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index('Date')\n",
    "    # set indices on both df to datetime\n",
    "    idx = pd.to_datetime(df_actions.index, infer_datetime_format=True)\n",
    "    df_actions.index=idx\n",
    "    tics = np.unique(df.tic)\n",
    "    n_tics = len(tics)\n",
    "    print(f'Number of tickers: {n_tics}')\n",
    "    print(f'Tickers: {tics}')\n",
    "    dategr = df.groupby('tic')\n",
    "    p_d={t:dategr.get_group(t).loc[:,'close'] for t in tics}\n",
    "    df_prices = pd.DataFrame.from_dict(p_d)\n",
    "    df_prices.index = df_prices.index.normalize()\n",
    "    return df_actions, df_prices, tics\n",
    "\n",
    "\n",
    "# prepares for integrating action and price files\n",
    "def link_prices_actions(df_a,\n",
    "                        df_p):\n",
    "    cols_a = [t + '_a' for t in df_a.columns]\n",
    "    df_a.columns = cols_a\n",
    "    cols_p = [t + '_p' for t in df_p.columns]\n",
    "    df_p.columns = cols_p\n",
    "    return df_a, df_p\n",
    "\n",
    "\n",
    "def sync_tickers(df_actions,df_tickers_p,tickers):\n",
    "    # Some DOW30 components may not be included in portfolio\n",
    "    # passed tickers includes all DOW30 components\n",
    "    # actions and ticker files may have different length indices\n",
    "    if len(df_actions) != len(df_tickers_p):\n",
    "        msng_dates = set(df_actions.index)^set(df_tickers_p.index)\n",
    "        try:\n",
    "            #assumption is prices has one additional timestamp (row)\n",
    "            df_tickers_p.drop(msng_dates,inplace=True)\n",
    "        except:\n",
    "            df_actions.drop(msng_dates,inplace=True)\n",
    "    df_actions, df_tickers_p = link_prices_actions(df_actions,df_tickers_p)\n",
    "    # identify any DOW components not in portfolio\n",
    "    t_not_in_a = [t for t in tickers if t + '_a' not in list(df_actions.columns)]\n",
    "  \n",
    "    # remove t_not_in_a from df_tickers_p\n",
    "    drop_cols = [t + '_p' for t in t_not_in_a]\n",
    "    df_tickers_p.drop(columns=drop_cols,inplace=True)\n",
    "    \n",
    "    # Tickers in portfolio\n",
    "    tickers_prtfl = [c.split('_')[0] for c in df_actions.columns]\n",
    "    return df_actions,df_tickers_p, tickers_prtfl\n",
    "\n",
    "def collect_performance_data(dfa,dfp,tics, dbg=False):\n",
    "    \n",
    "    perf_data = {}\n",
    "    # In current version, files columns include secondary identifier\n",
    "    for t in tics:\n",
    "        # actions: purchase/sale of DOW equities\n",
    "        acts = dfa['_'.join([t,'a'])].values\n",
    "        # ticker prices\n",
    "        prices = dfp['_'.join([t,'p'])].values\n",
    "        # market value of purchases/sales\n",
    "        tvals_init = np.multiply(acts,prices)\n",
    "        d={'actions':acts, 'prices':prices,'init_values':tvals_init}\n",
    "        perf_data[t]=d\n",
    "\n",
    "    return perf_data\n",
    "\n",
    "\n",
    "def calc_pnl_all(perf_dict, tics_all):\n",
    "    # calculate profit/loss for each ticker\n",
    "    print(f'Calculating profit/loss for each ticker')\n",
    "    pnl_all = {}\n",
    "    for tic in tics_all:\n",
    "        pnl_t = []\n",
    "        tic_data = perf_dict[tic]\n",
    "        init_values = tic_data['init_values']\n",
    "        acts = tic_data['actions']\n",
    "        prices = tic_data['prices']\n",
    "        cs = np.cumsum(acts)\n",
    "        args_s = [i + 1 for i in range(len(cs) - 1) if cs[i + 1] < cs[i]]\n",
    "        # tic actions with no sales\n",
    "        if not args_s:\n",
    "            pnl = complete_calc_buyonly(acts, prices, init_values)\n",
    "            pnl_all[tic] = pnl\n",
    "            continue\n",
    "        # copy acts: acts_rev will be revised based on closing/reducing init positions\n",
    "        pnl_all = execute_position_sales(tic,acts,prices,args_s,pnl_all)\n",
    "\n",
    "    return pnl_all\n",
    "\n",
    "\n",
    "def complete_calc_buyonly(actions, prices, init_values):\n",
    "    # calculate final pnl for each ticker assuming no sales\n",
    "    fnl_price = prices[-1]\n",
    "    final_values = np.multiply(fnl_price, actions)\n",
    "    pnl = np.subtract(final_values, init_values)\n",
    "    return pnl\n",
    "\n",
    "\n",
    "def execute_position_sales(tic,acts,prices,args_s,pnl_all):\n",
    "  # calculate final pnl for each ticker with sales\n",
    "    pnl_t = []\n",
    "    acts_rev = acts.copy()\n",
    "    # location of sales transactions\n",
    "    for s in args_s:  # s is scaler\n",
    "        # price_s = [prices[s]]\n",
    "        act_s = [acts_rev[s]]\n",
    "        args_b = [i for i in range(s) if acts_rev[i] > 0]\n",
    "        prcs_init_trades = prices[args_b]\n",
    "        acts_init_trades = acts_rev[args_b]\n",
    "  \n",
    "        # update actions for sales\n",
    "        # reduce/eliminate init values through trades\n",
    "        # always start with earliest purchase that has not been closed through sale\n",
    "        # selectors for purchase and sales trades\n",
    "        # find earliest remaining purchase\n",
    "        arg_sel = min(args_b)\n",
    "        # sel_s = len(acts_trades) - 1\n",
    "\n",
    "        # closing part/all of earliest init trade not yet closed\n",
    "        # sales actions are negative\n",
    "        # in this test case, abs_val of init and sales share counts are same\n",
    "        # zero-out sales actions\n",
    "        # market value of sale\n",
    "        # max number of shares to be closed: may be less than # originally purchased\n",
    "        acts_shares = min(abs(act_s.pop()), acts_rev[arg_sel])\n",
    "\n",
    "        # mv of shares when purchased\n",
    "        mv_p = abs(acts_shares * prices[arg_sel])\n",
    "        # mv of sold shares\n",
    "        mv_s = abs(acts_shares * prices[s])\n",
    "\n",
    "        # calc pnl\n",
    "        pnl = mv_s - mv_p\n",
    "        # reduce init share count\n",
    "        # close all/part of init purchase\n",
    "        acts_rev[arg_sel] -= acts_shares\n",
    "        acts_rev[s] += acts_shares\n",
    "        # calculate pnl for trade\n",
    "        # value of associated purchase\n",
    "        \n",
    "        # find earliest non-zero positive act in acts_revs\n",
    "        pnl_t.append(pnl)\n",
    "    \n",
    "    pnl_op = calc_pnl_for_open_positions(acts_rev, prices)\n",
    "    #pnl_op is list\n",
    "    # add pnl_op results (if any) to pnl_t (both lists)\n",
    "    pnl_t.extend(pnl_op)\n",
    "    #print(f'Total pnl for {tic}: {np.sum(pnl_t)}')\n",
    "    pnl_all[tic] = np.array(pnl_t)\n",
    "    return pnl_all\n",
    "\n",
    "\n",
    "def calc_pnl_for_open_positions(acts,prices):\n",
    "    # identify any positive share values after accounting for sales\n",
    "    pnl = []\n",
    "    fp = prices[-1] # last price\n",
    "    open_pos_arg = np.argwhere(acts>0)\n",
    "    if len(open_pos_arg)==0:\n",
    "        return pnl # no open positions\n",
    "\n",
    "    mkt_vals_open = np.multiply(acts[open_pos_arg], prices[open_pos_arg])\n",
    "    # mkt val at end of testing period\n",
    "    # treat as trades for purposes of calculating pnl at end of testing period\n",
    "    mkt_vals_final = np.multiply(fp, acts[open_pos_arg])\n",
    "    pnl_a = np.subtract(mkt_vals_final, mkt_vals_open)\n",
    "    #convert to list\n",
    "    pnl = [i[0] for i in pnl_a.tolist()]\n",
    "    #print(f'Market value of open positions at end of testing {pnl}')\n",
    "    return pnl\n",
    "\n",
    "\n",
    "def calc_trade_perf(pnl_d):\n",
    "    # calculate trade performance metrics\n",
    "    perf_results = {}\n",
    "    for t,pnl in pnl_d.items():\n",
    "        wins = pnl[pnl>0]  # total val\n",
    "        losses = pnl[pnl<0]\n",
    "        n_wins = len(wins)\n",
    "        n_losses = len(losses)\n",
    "        n_trades = n_wins + n_losses\n",
    "        wins_val = np.sum(wins)\n",
    "        losses_val = np.sum(losses)\n",
    "        wins_avg = 0 if n_wins==0 else np.mean(wins)\n",
    "        #print(f'{t} n_wins: {n_wins} n_losses: {n_losses}')\n",
    "        losses_avg = 0 if n_losses==0 else np.mean(losses)\n",
    "        d = {'# trades':n_trades,'# wins':n_wins,'# losses':n_losses,\n",
    "             'wins total value':wins_val, 'wins avg value':wins_avg,\n",
    "             'losses total value':losses_val, 'losses avg value':losses_avg,}\n",
    "        perf_results[t] = d\n",
    "    return perf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning using Optuna}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_ddpg_params_all(trial:optuna.Trial,\n",
    "#                            # fixed values from previous study\n",
    "#                            learning_rate=0.0103,\n",
    "#                            batch_size=128,\n",
    "#                            buffer_size=int(1e6)):\n",
    "\n",
    "#     gamma = trial.suggest_categorical(\"gamma\", [0.94, 0.96, 0.98])\n",
    "#     # Polyak coeff\n",
    "#     tau = trial.suggest_categorical(\"tau\", [0.08, 0.1, 0.12])\n",
    "\n",
    "#     train_freq = trial.suggest_categorical(\"train_freq\", [512,768,1024])\n",
    "#     gradient_steps = train_freq\n",
    "    \n",
    "#     noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
    "#     noise_std = trial.suggest_categorical(\"noise_std\", [.1,.2,.3] )\n",
    "\n",
    "#     # NOTE: Add \"verybig\" to net_arch when tuning HER (see TD3)\n",
    "#     net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"big\"])\n",
    "#     # activation_fn = trial.suggest_categorical('activation_fn', [nn.Tanh, nn.ReLU, nn.ELU, nn.LeakyReLU])\n",
    "\n",
    "#     net_arch = {\n",
    "#         \"small\": [64, 64],\n",
    "#         \"medium\": [256, 256],\n",
    "#         \"big\": [512, 512],\n",
    "#     }[net_arch]\n",
    "  \n",
    "#     hyperparams = {\n",
    "#         \"batch_size\": batch_size,\n",
    "#         \"buffer_size\": buffer_size,\n",
    "#         \"gamma\": gamma,\n",
    "#         \"gradient_steps\": gradient_steps,\n",
    "#         \"learning_rate\": learning_rate,\n",
    "#         \"tau\": tau,\n",
    "#         \"train_freq\": train_freq,\n",
    "#         #\"noise_std\": noise_std,\n",
    "#         #\"noise_type\": noise_type,\n",
    "        \n",
    "#         \"policy_kwargs\": dict(net_arch=net_arch)\n",
    "#     }\n",
    "#     return hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ddpg_params(trial:optuna.Trial):\n",
    "    # Size of the replay buffer\n",
    "    buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(1e5), int(1e6)])\n",
    "#     tau = trial.suggest_categorical(\"tau\", [0.01, 0.001, 0.1])\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
    "#     learning_rate_critic = trial.suggest_loguniform(\"learning_rate_critic\", 1e-5, 1e-1)\n",
    "#     learning_rate_actor = 10**trial.suggest_int('logval', -5, 0)\n",
    "#     learning_rate_critic = 10**trial.suggest_int('logval', -5, 0)\n",
    "    \n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512])\n",
    "\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\"])\n",
    "\n",
    "    net_arch = {\n",
    "        \"small\": [64, 64],\n",
    "        \"medium\": [256, 256],\n",
    "        \"default\": [400, 400],\n",
    "        \"big\": [512, 512],\n",
    "    }[net_arch]\n",
    "\n",
    "    return {\n",
    "#             \n",
    "#             \"tau\": tau,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"buffer_size\": buffer_size,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"layer_1_size\": net_arch[0],\n",
    "            \"layer_2_size\": net_arch[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingCallback:\n",
    "    def __init__(self, threshold, trial_number, patience):\n",
    "        '''\n",
    "        threshold:int tolerance for increase in objective\n",
    "        trial_number: int Prune after minimum number of trials\n",
    "        patience: int patience for the threshold\n",
    "        '''\n",
    "        self.threshold = threshold\n",
    "        self.trial_number  = trial_number\n",
    "        self.patience = patience\n",
    "        print(f'Callback threshold {self.threshold}, \\\n",
    "            trial_number {self.trial_number}, \\\n",
    "            patience {self.patience}')\n",
    "        self.cb_list = [] #Trials list for which threshold is reached\n",
    "        \n",
    "    def __call__(self, study:optuna.study, frozen_trial:optuna.Trial):\n",
    "        #Setting the best value in the current trial\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "\n",
    "        #Checking if the minimum number of trials have pass\n",
    "        if frozen_trial.number >self.trial_number:\n",
    "            previous_best_value = study.user_attrs.get(\"previous_best_value\",None)\n",
    "            #Checking if the previous and current objective values have the same sign\n",
    "            if previous_best_value * study.best_value >=0:\n",
    "                #Checking for the threshold condition\n",
    "                if abs(previous_best_value-study.best_value) < self.threshold: \n",
    "                    self.cb_list.append(frozen_trial.number)\n",
    "                    #If threshold is achieved for the patience amount of time\n",
    "                    if len(self.cb_list)>self.patience:\n",
    "                        print('The study stops now...')\n",
    "                        print('With number',frozen_trial.number ,'and value ',frozen_trial.value)\n",
    "                        print('The previous and current best values are {} and {} respectively'\n",
    "                              .format(previous_best_value, study.best_value))\n",
    "                        study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-29 08:09:27,134]\u001b[0m Trial 9 finished with value: 1.9684022492229998 and parameters: {'buffer_size': 1000000, 'learning_rate': 0.012392298037713417, 'batch_size': 128, 'net_arch': 'medium'}. Best is trial 3 with value: 2.91729969004257.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n",
      "Number of tickers: 29\n",
      "Tickers: ['AAPL' 'AMGN' 'AXP' 'BA' 'CAT' 'CRM' 'CSCO' 'CVX' 'DIS' 'GS' 'HD' 'HON'\n",
      " 'IBM' 'INTC' 'JNJ' 'JPM' 'KO' 'MCD' 'MMM' 'MRK' 'MSFT' 'NKE' 'PG' 'TRV'\n",
      " 'UNH' 'V' 'VZ' 'WBA' 'WMT']\n",
      "Calculating profit/loss for each ticker\n",
      "Ratio Avg Win/Avg Loss: 1.9684022492229998\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import sys   \n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "def objective(trial:optuna.Trial):\n",
    "    #Trial will suggest a set of hyperparamters from the specified range\n",
    "\n",
    "    # Optional to optimize larger set of parameters\n",
    "    # hyperparameters = sample_ddpg_params_all(trial)\n",
    "\n",
    "    # Optimize buffer size, batch size, learning rate\n",
    "    hyperparameters = sample_ddpg_params(trial)\n",
    "    print(f'Hyperparameters from objective: {hyperparameters}')\n",
    "    \n",
    "#     policy_kwargs = None  # default\n",
    "#     if 'policy_kwargs' in hyperparameters.keys():\n",
    "#         policy_kwargs = hyperparameters['policy_kwargs']\n",
    "#         del hyperparameters['policy_kwargs']\n",
    "    #print(f'Policy keyword arguments {policy_kwargs}')\n",
    "#     model_ddpg = agent.get_model(\"ddpg\",\n",
    "#                                policy_kwargs = policy_kwargs,\n",
    "#                                model_kwargs = hyperparameters )\n",
    "#     #You can increase it for better comparison\n",
    "#     trained_ddpg = agent.train_model(model=model_ddpg,\n",
    "#                                    tb_log_name=\"ddpg\",\n",
    "#                                    total_timesteps=total_timesteps)\n",
    "    ACTOR_LR = hyperparameters[\"learning_rate\"]\n",
    "    CRITIC_LR = hyperparameters[\"learning_rate\"]\n",
    "    BATCH_SIZE = hyperparameters[\"batch_size\"]\n",
    "    TAU = 0.001\n",
    "    LAYER_1_SIZE = hyperparameters[\"layer_1_size\"]\n",
    "    LAYER_2_SIZE = hyperparameters[\"layer_2_size\"]\n",
    "    buffer_size = hyperparameters[\"buffer_size\"]\n",
    "    \n",
    "    model_ddpg = Agent(alpha=ACTOR_LR, beta=CRITIC_LR, ckp_dir='./models', input_dims=state_space, tau=TAU,\n",
    "              batch_size=BATCH_SIZE, layer1_size=LAYER_1_SIZE, layer2_size=LAYER_2_SIZE, max_size=buffer_size,\n",
    "              n_actions=stock_dimension)\n",
    "    \n",
    "    trained_ddpg = model_ddpg.train_model(\n",
    "                        total_episodes=total_episodes, train_from_scratch=True, \n",
    "                        env=e_train_gym, env_kwargs=env_kwargs, save_ckp=False, ckp_save_freq=0,\n",
    "                        use_wandb=False)\n",
    "    \n",
    "#     trained_ddpg.save('models/ddpg_{}.pth'.format(trial.number))\n",
    "    trained_ddpg.save_checkpoint(checkpoint_name='ddpg_{}.pt'.format(trial.number), last_episode=trained_ddpg.episode)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    #For the given hyperparamters, determine the account value in the trading period\n",
    "    \n",
    "#     df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "#     model=trained_ddpg, \n",
    "#     environment = e_trade_gym)\n",
    "    df_account_value, df_actions, cumulative_rewards_test = trade_on_test_df(df=trade, \n",
    "                                                                             model=trained_ddpg, \n",
    "                                                                             train_df=train, \n",
    "                                                                             env_kwargs=env_kwargs)\n",
    "\n",
    "    # Calculate trade performance metric\n",
    "    # Currently ratio of average win and loss market values\n",
    "    tpm = calc_trade_perf_metric(df_actions,trade,tp_metric)\n",
    "    return tpm\n",
    "\n",
    "#Create a study object and specify the direction as 'maximize'\n",
    "#As you want to maximize sharpe\n",
    "#Pruner stops not promising iterations\n",
    "#Use a pruner, else you will get error related to divergence of model\n",
    "#You can also use Multivariate samplere\n",
    "#sampler = optuna.samplers.TPESampler(multivarite=True,seed=42)\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(study_name=\"ddpg_study\",direction='maximize',\n",
    "                        sampler = sampler, pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "logging_callback = LoggingCallback(threshold=lc_threshold,\n",
    "                               patience=lc_patience,\n",
    "                               trial_number=lc_trial_number)\n",
    "#You can increase the n_trials for a better search space scanning\n",
    "study.optimize(objective, n_trials=n_trials, catch=(ValueError,), callbacks=[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddpg_0.pt  ddpg_2.pt  ddpg_4.pt  ddpg_6.pt  ddpg_8.pt\r\n",
      "ddpg_1.pt  ddpg_3.pt  ddpg_5.pt  ddpg_7.pt  ddpg_9.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_ddpg_study_a_c_diff_seed_0_.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, \"final_ddpg_study_a_c_diff_seed_0_.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from finrl import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters after tuning {'buffer_size': 1000000, 'learning_rate': 0.03991178541854849, 'batch_size': 512, 'net_arch': 'medium'}\n"
     ]
    }
   ],
   "source": [
    "#Get the best hyperparamters\n",
    "print('Hyperparameters after tuning',study.best_params)\n",
    "# print('Hyperparameters before tuning',config.DDPG_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=3, values=[2.91729969004257], datetime_start=datetime.datetime(2022, 7, 29, 7, 16, 0, 628849), datetime_complete=datetime.datetime(2022, 7, 29, 7, 28, 2, 299906), params={'buffer_size': 1000000, 'learning_rate': 0.03991178541854849, 'batch_size': 512, 'net_arch': 'medium'}, distributions={'buffer_size': CategoricalDistribution(choices=(10000, 100000, 1000000)), 'learning_rate': LogUniformDistribution(high=0.1, low=1e-05), 'batch_size': CategoricalDistribution(choices=(32, 64, 128, 256, 512)), 'net_arch': CategoricalDistribution(choices=('small', 'medium', 'big'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=3, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import DDPG\n",
    "# tuned_model_ddpg = DDPG.load('models/ddpg_{}.pth'.format(study.best_trial.number),env=env_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint...(./trained_models/daily_data_lin_tuned_seed_0/agent_ep_10.pt)\n",
      "Loaded model at episode 11 from ./trained_models/daily_data_lin_tuned_seed_0/agent_ep_10.pt\n"
     ]
    }
   ],
   "source": [
    "# from config import *\n",
    "\n",
    "agent = Agent(alpha= 0.03991178541854849, beta=0.03991178541854849, ckp_dir='', input_dims=state_space, tau=0.001,\n",
    "              batch_size=512, layer1_size=256, layer2_size=256, max_size=1000000,\n",
    "              n_actions=stock_dimension)\n",
    "            \n",
    "_ = agent.load_checkpoint('./models/ddpg_{}.pt'.format(3))\n",
    "# _ = agent.load_checkpoint('./trained_models/daily_data_lin_tuned_seed_0/agent_ep_10.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trading period account value with tuned model\n",
    "# df_account_value_tuned, df_actions_tuned = DRLAgent.DRL_prediction(\n",
    "#     model=tuned_model_ddpg, \n",
    "#     environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_tuned, df_actions_tuned, cum_rewards_test = trade_on_test_df(df=trade, model=agent, train_df=train, env_kwargs=env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>1.000269e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>9.984094e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>9.935191e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>9.913347e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>1.661886e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>1.666838e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>1.677156e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>1.664127e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>1.679584e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1094 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  account_value\n",
       "0     2016-01-04   1.000000e+06\n",
       "1     2016-01-05   1.000269e+06\n",
       "2     2016-01-06   9.984094e+05\n",
       "3     2016-01-07   9.935191e+05\n",
       "4     2016-01-08   9.913347e+05\n",
       "...          ...            ...\n",
       "1089  2020-05-01   1.661886e+06\n",
       "1090  2020-05-04   1.666838e+06\n",
       "1091  2020-05-05   1.677156e+06\n",
       "1092  2020-05-06   1.664127e+06\n",
       "1093  2020-05-07   1.679584e+06\n",
       "\n",
       "[1094 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trade_perf_metric(df_actions, \n",
    "                          perf_stats_all,\n",
    "                          trade, \n",
    "                          tp_metric):\n",
    "    tpm = calc_trade_perf_metric(df_actions,trade,tp_metric)\n",
    "    trp_metric = {'Value':tpm}\n",
    "    df2 = pd.DataFrame(trp_metric,index=['Trade_Perf'])\n",
    "    perf_stats_all = perf_stats_all.append(df2)\n",
    "    return perf_stats_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./tuning', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "df_actions_tuned.to_csv(\"./\"+\"tuning\"+\"/tuned_actions_\" +now+ '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20220729-08h24'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "==============Pruned Model===========\n",
      "Annual return          0.126872\n",
      "Cumulative returns     0.679584\n",
      "Annual volatility      0.139565\n",
      "Sharpe ratio           0.926881\n",
      "Calmar ratio           0.684726\n",
      "Stability              0.934761\n",
      "Max drawdown          -0.185289\n",
      "Omega ratio            1.195467\n",
      "Sortino ratio          1.277331\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.993224\n",
      "Daily value at risk   -0.017070\n",
      "dtype: float64\n",
      "Number of tickers: 29\n",
      "Tickers: ['AAPL' 'AMGN' 'AXP' 'BA' 'CAT' 'CRM' 'CSCO' 'CVX' 'DIS' 'GS' 'HD' 'HON'\n",
      " 'IBM' 'INTC' 'JNJ' 'JPM' 'KO' 'MCD' 'MMM' 'MRK' 'MSFT' 'NKE' 'PG' 'TRV'\n",
      " 'UNH' 'V' 'VZ' 'WBA' 'WMT']\n",
      "Calculating profit/loss for each ticker\n",
      "Ratio Avg Win/Avg Loss: 2.7284904385312796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neeraj/anaconda3/envs/ddpg_trading/lib/python3.8/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n",
      "/tmp/ipykernel_5265/490943077.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  perf_stats_all = perf_stats_all.append(df2)\n"
     ]
    }
   ],
   "source": [
    "#Backtesting with our pruned model\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "print(\"==============Pruned Model===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all_tuned = backtest_stats(account_value=df_account_value_tuned)\n",
    "perf_stats_all_tuned = pd.DataFrame(perf_stats_all_tuned)\n",
    "perf_stats_all_tuned.columns = ['Value']\n",
    "# add trade performance metric\n",
    "perf_stats_all_tuned = \\\n",
    "  add_trade_perf_metric(df_actions_tuned,\n",
    "                        perf_stats_all_tuned,\n",
    "                        trade,\n",
    "                        tp_metric)\n",
    "perf_stats_all_tuned.to_csv(\"./\"+\"tuning\"+\"/perf_stats_all_tuned_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BASELINE_TICKER_NAME_BACKTESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neeraj/anaconda3/envs/ddpg_trading/lib/python3.8/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.126872\n",
      "Cumulative returns     0.679584\n",
      "Annual volatility      0.139565\n",
      "Sharpe ratio           0.926881\n",
      "Calmar ratio           0.684726\n",
      "Stability              0.934761\n",
      "Max drawdown          -0.185289\n",
      "Omega ratio            1.195467\n",
      "Sortino ratio          1.277331\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.993224\n",
      "Daily value at risk   -0.017070\n",
      "dtype: float64\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (1093, 8)\n",
      "Annual return          0.077076\n",
      "Cumulative returns     0.379948\n",
      "Annual volatility      0.200509\n",
      "Sharpe ratio           0.471618\n",
      "Calmar ratio           0.207830\n",
      "Stability              0.796212\n",
      "Max drawdown          -0.370862\n",
      "Omega ratio            1.114135\n",
      "Sortino ratio          0.645466\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.820444\n",
      "Daily value at risk   -0.024886\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neeraj/anaconda3/envs/ddpg_trading/lib/python3.8/site-packages/finrl/meta/preprocessor/yahoodownloader.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df = data_df.append(temp_df)\n",
      "/home/neeraj/anaconda3/envs/ddpg_trading/lib/python3.8/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "# DJI for the same time\n",
    "results_df = get_comparison_df(df_account_value_tuned, BASELINE_TICKER_NAME_BACKTESTING)\n",
    "train_values = np.zeros(len(results_df))\n",
    "train_values[list(results_df.metric).index('Cumulative returns')] = cum_rewards_test[-1]\n",
    "train_values[list(results_df.metric).index('Max drawdown')] = min(cum_rewards_test)\n",
    "results_df['train_data'] = train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THIS DF_ACCOUNT_VALUE_TUNED\n",
    "\n",
    "account_value_csv_name = f'account_value_test_tuning.csv'\n",
    "actions_csv_name = f'daily_actions_test_tuning.csv'\n",
    "results_table_name = f'return_comparison_test.csv'\n",
    "df_account_value_tuned.to_csv(os.path.join('./tuning', account_value_csv_name))\n",
    "df_actions_tuned.to_csv(os.path.join('./tuning', actions_csv_name))\n",
    "results_df.to_csv(os.path.join('./tuning', results_table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now train with not tuned hyperaparameters\n",
    "#Default config.ddpg_PARAMS\n",
    "non_tuned_model_ddpg = agent.get_model(\"ddpg\",model_kwargs = config.DDPG_PARAMS )\n",
    "trained_ddpg = agent.train_model(model=non_tuned_model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backtesting for not tuned hyperparamters\n",
    "print(\"==============Get Backtest Results===========\")\n",
    "print(\"============Default Hyperparameters==========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.columns = ['Value']\n",
    "# add trade performance metric\n",
    "perf_stats_all = add_trade_perf_metric(df_actions,\n",
    "                        perf_stats_all,\n",
    "                        trade,\n",
    "                        tp_metric)\n",
    "perf_stats_all.to_csv(\"./\"+\"tuning\"+\"/perf_stats_all_untuned_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = joblib.load(\"final_ddpg_study__.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Certainly you can afford more number of trials for further optimization\n",
    "from optuna.visualization import plot_optimization_history\n",
    "fig = plot_optimization_history(study)\n",
    "#\"./\"+config.RESULTS_DIR+\n",
    "fig.write_image(\"./\"+\"tuning\"+\"/opt_hist.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamters importance\n",
    "\n",
    "try:\n",
    "    fig = plot_param_importances(study)\n",
    "    fig.write_image(\"./\"+config.RESULTS_DIR+\"/params_importances.png\")\n",
    "    fig.show()\n",
    "except:\n",
    "    print('Cannot calculate hyperparameter importances: no variation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_edf(study)\n",
    "# fig.write_image(\"./\"+\"tuning\"+\"/emp_dist_func.png\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
